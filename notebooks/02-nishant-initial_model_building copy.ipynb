{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline \n",
    "\n",
    "* Setup \n",
    "* Create train, dev, & test set \n",
    "* Performance Metric: Precision\n",
    "* Select a model - choose between RF, XGBoost, & LR \n",
    "* Report Generalization error\n",
    "* Iterate - engineer new features, add more data. Possibly carry this out on a different notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1317 entries, 0 to 1316\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   day            1317 non-null   int8          \n",
      " 1   venue          1317 non-null   int8          \n",
      " 2   opponent       1317 non-null   int8          \n",
      " 3   formation      1317 non-null   int8          \n",
      " 4   hour           1317 non-null   int8          \n",
      " 5   datetime       1317 non-null   datetime64[ns]\n",
      " 6   team           1317 non-null   object        \n",
      " 7   gf_rolling     1317 non-null   float64       \n",
      " 8   ga_rolling     1317 non-null   float64       \n",
      " 9   sh_rolling     1317 non-null   float64       \n",
      " 10  sot_rolling    1317 non-null   float64       \n",
      " 11  dist_rolling   1317 non-null   float64       \n",
      " 12  fk_rolling     1317 non-null   float64       \n",
      " 13  pk_rolling     1317 non-null   float64       \n",
      " 14  pkatt_rolling  1317 non-null   float64       \n",
      " 15  target         1317 non-null   int64         \n",
      " 16  season         1317 non-null   int64         \n",
      " 17  Year           1317 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(3), int8(5), object(1)\n",
      "memory usage: 150.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as  np \n",
    "import sklearn as sk\n",
    "\n",
    "matches = pd.read_pickle('../data/interim/matches_interim.pkl')\n",
    "matches['Year'] = pd.to_datetime(matches.datetime).dt.year\n",
    "matches.info() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, dev, & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original \n",
    "# # Training set \n",
    "\n",
    "# matches2021 = matches.query('season == 2021')\n",
    "\n",
    "# X_train = matches2021.drop(['target','datetime','team', 'season'], axis = 1)\n",
    "# Y_train = matches2021['target']\n",
    "\n",
    "# # Dev Set & Test set \n",
    "\n",
    "# matches2022 = matches.query('season == 2022')\n",
    "\n",
    "# matches2022.drop(['datetime','team','season'], axis = 1, inplace = True)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_test, X_dev, Y_test, Y_dev =  train_test_split(matches2022.drop('target', axis = 1), matches2022['target'],\n",
    "#                                                  test_size = 0.50, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "# X_test, X_main_test, Y_test, Y_main_test =   train_test_split(matches2022.drop('target', axis = 1), matches2022['target'],\n",
    "#                                                  test_size = 0.30, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/4dbklqz57h5c3nsx984r5c840000gn/T/ipykernel_9769/620287768.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches2022.drop(['datetime','team','season', 'Year'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Note: This is experiment \n",
    "\n",
    "# Training set \n",
    "\n",
    "years = [ 2020, 2021]\n",
    "\n",
    "matches2021 = matches.query('Year in @years')\n",
    "\n",
    "X_train = matches2021.drop(['target','datetime','team', 'season','Year'], axis = 1)\n",
    "Y_train = matches2021['target']\n",
    "\n",
    "# Dev Set & Test set \n",
    "\n",
    "matches2022 = matches.query('Year == 2022')\n",
    "\n",
    "matches2022.drop(['datetime','team','season', 'Year'], axis = 1, inplace = True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_test, X_dev, Y_test, Y_dev =  train_test_split(matches2022.drop('target', axis = 1), matches2022['target'],\n",
    "                                                 test_size = 0.50, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "# X_test, X_main_test, Y_test, Y_main_test =   train_test_split(matches2022.drop('target', axis = 1), matches2022['target'],\n",
    "#                                                  test_size = 0.30, shuffle = True, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the datasets \n",
    "\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "# os.mkdir('../data/interim/train_test_sets')\n",
    "X_train.to_pickle('../data/interim/train_test_sets/X_train.pkl')\n",
    "X_dev.to_pickle('../data/interim/train_test_sets/X_dev.pkl')\n",
    "X_test.to_pickle('../data/interim/train_test_sets/X_test.pkl')\n",
    "X_main_test.to_pickle('../data/interim/train_test_sets/X_main_test.pkl')\n",
    "\n",
    "Y_train.to_pickle('../data/interim/train_test_sets/Y_train.pkl')\n",
    "Y_dev.to_pickle('../data/interim/train_test_sets/Y_dev.pkl')\n",
    "Y_test.to_pickle('../data/interim/train_test_sets/Y_test.pkl')\n",
    "Y_main_test.to_pickle('../data/interim/train_test_sets/Y_main_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select A Model \n",
    "\n",
    "# Training Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Training XGBoost \n",
    "\n",
    "import xgboost as xgb \n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Training Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter= 1000).fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5909090909090909,\n",
       " 0.5526315789473685,\n",
       " 0.5384615384615384,\n",
       " 0.5909090909090909)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting & Comparing Performance \n",
    "\n",
    "# Performance Measure: Precision on dev set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "y_dev_rg_pred = rf.predict(X_dev)\n",
    "y_dev_xgb_pred = xgb_model.predict(X_dev)\n",
    "y_dev_lr_pred = lr.predict(X_dev)\n",
    "\n",
    "rg_precision = precision_score(Y_dev, y_dev_rg_pred)\n",
    "xgb_precision = precision_score(Y_dev,y_dev_xgb_pred)\n",
    "lr_precision = precision_score(Y_dev ,y_dev_lr_pred)\n",
    "\n",
    "best_precision = max(rg_precision,xgb_precision,lr_precision)\n",
    "\n",
    "rg_precision, xgb_precision, lr_precision, best_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.5595238095238095)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance Measure: Precision on train set \n",
    "\n",
    "y_train_rf_pred = rf.predict(X_train)\n",
    "y_train_xgb_pred = xgb_model.predict(X_train)\n",
    "y_train_lr_pred = lr.predict(X_train)\n",
    "\n",
    "\n",
    "rg_precision_train = precision_score(Y_train, y_train_rf_pred)\n",
    "xgb_precision_train = precision_score(Y_train, y_train_xgb_pred)\n",
    "lr_precision_train = precision_score(Y_train, y_train_lr_pred)\n",
    "\n",
    "\n",
    "rg_precision_train, xgb_precision_train, lr_precision_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb, & rg have high variance problem, lr has high bias problem. LR currently performs best on the dev set but the precision score is 66%. Probably training a single decision tree classifier can help to get a better precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.044444444444444446, 0.5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "y_dev_sgd_pred =  sgd_clf.predict(X_dev)\n",
    "y_train_sgd_pred = sgd_clf.predict(X_train)\n",
    "\n",
    "sgd_precision = precision_score(y_dev_sgd_pred, Y_dev)\n",
    "sgd_precision_train = precision_score(Y_train, y_train_sgd_pred)\n",
    "\n",
    "sgd_precision, sgd_precision_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_clf.fit(X_train, Y_train)\n",
    "\n",
    "y_dev_dt_pred =  dt_clf.predict(X_dev)\n",
    "y_train_dt_pred = dt_clf.predict(X_train)\n",
    "\n",
    "dt_precision = precision_score(y_dev_dt_pred, Y_dev)\n",
    "dt_precision_train = precision_score(Y_train, y_train_dt_pred)\n",
    "\n",
    "dt_precision, dt_precision_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD has a high bias and high variance problem, dt has a high variance problem. Logistic Regression is the model to go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selected - Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "* LR Precision on dev = 66%\n",
    "* LR Precision on train = 52.3 %\n",
    "* To solve for high bias.\n",
    "* Optimize feature vector for gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data performance for Logistic Regression \n",
    "\n",
    "# Load models\n",
    "\n",
    "import pickle\n",
    "\n",
    "lr = pickle.load(open('../models/LogisticRegression_v1.pkl','rb'))\n",
    "xgb_model = pickle.load(open('../models/XGBoost_v1.pkl', 'rb'))\n",
    "rf = pickle.load(open('../models/RandomForest_v1.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the model on test data \n",
    "\n",
    "\n",
    "y_test_lr_predict = rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "\n",
    "lr_precision_main = precision_score(Y_test, y_test_lr_predict, average= 'binary')\n",
    "lr_precision_main # Generalization performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Steps\n",
    "\n",
    "Data \n",
    "\n",
    "1.  Preserve the opponent column to enable filtering of predictions.\n",
    "2.  Add the remaining numerical columns as predictors.\n",
    "3.  Scale & normalize the data.\n",
    "\n",
    "Model\n",
    "\n",
    "1. Conduct Hyperparameter tuning on the newly trained model using RandomizedSearchCV to find the best parameters for the data. \n",
    "2. Test the new model against the test_set.\n",
    "3. If the model performs better use it and report the general performance using all of 2022 data. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DQ-Predict_EPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
